{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYBRID OF TEXT EXTRACTION TOOLS WITH TESSERACT OCR. CONVERT PDF TO MARKDOWN FORMAT.\n",
    "\n",
    "import os\n",
    "import fitz\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import pypandoc\n",
    "\n",
    "\n",
    "def extract_text_or_perform_ocr(pdf_path, page_number):\n",
    "    \"\"\"Extracts text from a PDF page; performs OCR if the page is image-based.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc[page_number]\n",
    "    text = page.get_text().strip()\n",
    "    doc.close()\n",
    "\n",
    "    if not text:  # If no text, perform OCR on the page\n",
    "        images = convert_from_path(pdf_path, first_page=page_number + 1, last_page=page_number + 1)\n",
    "        text = pytesseract.image_to_string(images[0])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def convert_pdf_to_md(pdf_path, output_path):\n",
    "    \"\"\"Converts a PDF file to Markdown format using Pandoc.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    # Extract text from each page (with OCR for image-based pages)\n",
    "    texts = [extract_text_or_perform_ocr(pdf_path, pn) for pn in range(len(doc))]\n",
    "    doc.close()\n",
    "\n",
    "    full_text = '\\n\\n'.join(texts)\n",
    "\n",
    "    # Writing the full extracted text to a temporary .txt file\n",
    "    temp_txt_path = \"temp_extracted_text.txt\"\n",
    "    with open(temp_txt_path, 'w', encoding='utf-8') as temp_file:\n",
    "        temp_file.write(full_text)\n",
    "\n",
    "    # Convert the text file to Markdown using Pandoc\n",
    "    output_md = pypandoc.convert_file(temp_txt_path, 'md', format='markdown', outputfile=output_path)\n",
    "\n",
    "    os.remove(temp_txt_path)  # Clean up the temporary file\n",
    "\n",
    "    return output_md\n",
    "\n",
    "def batch_convert_pdf_to_md(pdf_folder, output_folder):\n",
    "    \"\"\"Converts all PDF files in a folder to Markdown format.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for pdf_file in os.listdir(pdf_folder):\n",
    "        if pdf_file.lower().endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "            md_filename = os.path.splitext(pdf_file)[0] + '.txt'\n",
    "            output_path = os.path.join(output_folder, md_filename)\n",
    "            convert_pdf_to_md(pdf_path, output_path)\n",
    "            print(f\"Converted '{pdf_file}' to Markdown format as '{md_filename}'.\")\n",
    "\n",
    "# Example usage\n",
    "pdf_folder = 'pdf'\n",
    "output_folder = 'txt'\n",
    "batch_convert_pdf_to_md(pdf_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTEWRNATIVE EXTRACTION TOOLS WITH EASYOCR. CONVERT PDF TO MARKDOWN FORMAT.\n",
    "\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from pdf2image import convert_from_path\n",
    "import easyocr\n",
    "import pypandoc\n",
    "import numpy as np  # Add this import at the beginning of your script\n",
    "\n",
    "def extract_text_or_perform_ocr(pdf_path, page_number):\n",
    "    \"\"\"Extracts text from a PDF page; performs OCR if the page is image-based.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc[page_number]\n",
    "    text = page.get_text().strip()\n",
    "    doc.close()\n",
    "\n",
    "    if not text:  # If no text, perform OCR on the page\n",
    "        images = convert_from_path(pdf_path, first_page=page_number + 1, last_page=page_number + 1)\n",
    "        reader = easyocr.Reader(['en'])  # Initialize EasyOCR reader, specify language as needed\n",
    "        image_np = np.array(images[0])  # Convert PIL image to NumPy array\n",
    "        results = reader.readtext(image_np, paragraph=True)  # Use `paragraph` for better grouping\n",
    "        text = ' '.join([result[1] for result in results])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def convert_pdf_to_md(pdf_path, output_path):\n",
    "    \"\"\"Converts a PDF file to Markdown format using Pandoc.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    texts = [extract_text_or_perform_ocr(pdf_path, pn) for pn in range(len(doc))]\n",
    "    doc.close()\n",
    "\n",
    "    full_text = '\\n\\n'.join(texts)\n",
    "    temp_txt_path = \"temp_extracted_text.txt\"\n",
    "    with open(temp_txt_path, 'w', encoding='utf-8') as temp_file:\n",
    "        temp_file.write(full_text)\n",
    "\n",
    "    output_md = pypandoc.convert_file(temp_txt_path, 'md', format='markdown', outputfile=output_path)\n",
    "    os.remove(temp_txt_path)  # Clean up the temporary file\n",
    "\n",
    "    return output_md\n",
    "\n",
    "def batch_convert_pdf_to_md(pdf_folder, output_folder):\n",
    "    \"\"\"Converts all PDF files in a folder to Markdown format.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for pdf_file in os.listdir(pdf_folder):\n",
    "        if pdf_file.lower().endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "            md_filename = os.path.splitext(pdf_file)[0] + '.txt'\n",
    "            output_path = os.path.join(output_folder, md_filename)\n",
    "            convert_pdf_to_md(pdf_path, output_path)\n",
    "            print(f\"Converted '{pdf_file}' to Markdown format as '{md_filename}'.\")\n",
    "\n",
    "# Example usage\n",
    "pdf_folder = 'pdf'\n",
    "output_folder = 'txt'\n",
    "batch_convert_pdf_to_md(pdf_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def process_text(text):\n",
    "    text = re.sub(r\"([a-zA-Z])(\\n)([A-Z])\", r\"\\1. \\3\", text)  # Adds missing dot between sentences split across lines.\n",
    "    text = re.sub(r\"([a-zA-Z])\\n\", r\"\\1 \", text)  # Removes inappropriate line breaks within paragraphs.\n",
    "    #text = re.sub(r\"\\s{2,}\", \" \", text)  # Replace multiple spaces with a single space, if needed.\n",
    "    return text\n",
    "\n",
    "def process_files(directory_path):\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(\"Directory does not exist:\", directory_path)\n",
    "        return\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory_path, filename)\n",
    "            try:\n",
    "                with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "\n",
    "                processed_content = process_text(content)\n",
    "\n",
    "                # Change the file extension from .md to .txt\n",
    "                txt_filename = os.path.splitext(filename)[0] + '.txt'\n",
    "                txt_filepath = os.path.join(directory_path, txt_filename)\n",
    "\n",
    "                with open(txt_filepath, 'w', encoding='utf-8') as file:\n",
    "                    file.write(processed_content)\n",
    "                print(f\"Processed and saved {txt_filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "directory_path = 'txt'\n",
    "process_files(directory_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work for .docx, .docm, and .dotx \n",
    "\n",
    "TODO:// .doc, .dot Check with Cesare if is not faster to do manual conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "import glob\n",
    "\n",
    "def process_document(doc_path):\n",
    "    print(f\"Processing {doc_path}...\")\n",
    "    doc = Document(doc_path)\n",
    "    output = []\n",
    "\n",
    "    for paragraph in doc.paragraphs:\n",
    "        output.append(paragraph.text + \"\\n\")\n",
    "\n",
    "    for table in doc.tables:\n",
    "        output.append(\"\\n[Table Start]\\n\")\n",
    "        for row in table.rows:\n",
    "            row_data = []\n",
    "            for cell in row.cells:\n",
    "                cell_text = cell.text.replace('\\n', ' ').strip()\n",
    "                row_data.append(cell_text)\n",
    "            output.append(\" | \".join(row_data) + \"\\n\")\n",
    "        output.append(\"[Table End]\\n\")\n",
    "    \n",
    "    return ''.join(output)\n",
    "\n",
    "def save_text(output_text, output_path):\n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(output_text)\n",
    "\n",
    "def process_folder(folder_path, output_folder):\n",
    "    for doc_path in glob.glob(os.path.join(folder_path, '*.docx')):\n",
    "        structured_text = process_document(doc_path)\n",
    "        \n",
    "        # Generate output path based on the document name\n",
    "        output_file_name = os.path.basename(doc_path).replace('.docx', '.txt')\n",
    "        output_path = os.path.join(output_folder, output_file_name)\n",
    "        \n",
    "        save_text(structured_text, output_path)\n",
    "        print(f\"Saved processed text to {output_path}\")\n",
    "\n",
    "# Path to your folder containing Word documents\n",
    "folder_path = \"C:\\\\Users\\\\david\\\\My Drive\\\\data\\\\analysis_git_data\\\\cgiar\\\\sample_word\"\n",
    "\n",
    "# Desired output folder for the text files\n",
    "output_folder ='C:\\\\Users\\\\david\\\\My Drive\\\\data\\\\analysis_git_data\\\\cgiar\\\\sample_processed_text'\n",
    "\n",
    "# Process all documents in the folder\n",
    "process_folder(folder_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel for .xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\10_10_web_Copy of AF RICE Madagascar PPR 2017-2018_final_10 June.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\10_10_web_Copy of AF RICE Madagascar PPR 2017-2018_final_10 June.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\10_10_Wor WEB_AF RICE Madagascar PPR 2017 -  Final_rev Sept 2018_3Dec.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\10_10_Wor WEB_AF RICE Madagascar PPR 2017 -  Final_rev Sept 2018_3Dec.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\12107_01. KEMITRAAN_PPR_Payo-Payo_Year II Final_Januari 2024 - for web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\12107_01. KEMITRAAN_PPR_Payo-Payo_Year II Final_Januari 2024 - for web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\12107_12107_KEMITRAAN_PPR1_South Sulawesi - for web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\12107_12107_KEMITRAAN_PPR1_South Sulawesi - for web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\1429_1429_PPR 2020-2021_Profonanpe_final_rev_VF_for_web.xlsx...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\openpyxl\\reader\\drawings.py:63: UserWarning: wmf image format is not supported so the image is being dropped\n",
      "  warn(msg)\n",
      "c:\\Python312\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "c:\\Python312\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\1429_1429_PPR 2020-2021_Profonanpe_final_rev_VF_for_web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\1429_PPR 2021-2022_Profonanpe_VF _ web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\1429_PPR 2021-2022_Profonanpe_VF _ web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\1430_1430_2020_Report_MS_ACREI_PPPR Year 2_for_web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\1430_1430_2020_Report_MS_ACREI_PPPR Year 2_for_web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\1430_1430_2021_Report_WMO_ACREI_PPR Year3 Revised v5c - for web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\1430_1430_2021_Report_WMO_ACREI_PPR Year3 Revised v5c - for web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\1430_1430_ACREI PPR Year 1_Oct 2019_Final_Public.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\1430_1430_ACREI PPR Year 1_Oct 2019_Final_Public.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\1430_2022_Report_WMO_ACREI_PPR Year4 v8 - for web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\1430_2022_Report_WMO_ACREI_PPR Year4 v8 - for web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\16_16_For web_ no procurement PIMS 4453 Revised PPR 2017 dated 29 April 2019.xlsx...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\16_16_For web_ no procurement PIMS 4453 Revised PPR 2017 dated 29 April 2019.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\16_16_For web_no procurement PIMS 4453 Revised PPR 2018 dated 29 April 2019.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\16_16_For web_no procurement PIMS 4453 Revised PPR 2018 dated 29 April 2019.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\26_26_web_4569_AF_Cook Island_PPR_Mar2017.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\26_26_web_4569_AF_Cook Island_PPR_Mar2017.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\3066_3066_web_Copy of PPR3 Colombia-Ecuador adjusted.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\3066_3066_web_Copy of PPR3 Colombia-Ecuador adjusted.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\3066_3066_WEB_PPR2_WFP Colombia-Ecuador_2019-2020 1 October 2020.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\3066_3066_WEB_PPR2_WFP Colombia-Ecuador_2019-2020 1 October 2020.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\3066_web_Copy of PPR4 Regional project Colombia-Ecuador Feb2023.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\3066_web_Copy of PPR4 Regional project Colombia-Ecuador Feb2023.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\31_31_Climate Proofing PPR-1_9 May 2018.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\31_31_Climate Proofing PPR-1_9 May 2018.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\36_36_For Website_Jordan _MoPIC_ AF_PPR 1_Jul16-Jul17_revised2.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\36_36_For Website_Jordan _MoPIC_ AF_PPR 1_Jul16-Jul17_revised2.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\36_36_Jordan_MoPIC_Adaptation Fund_PPR3_for_web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\36_36_Jordan_MoPIC_Adaptation Fund_PPR3_for_web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\36_36_WEB_Jordan MoPIC _July 2017-July 2018_v6.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\36_36_WEB_Jordan MoPIC _July 2017-July 2018_v6.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\36_7th PPR  Aug2022 - July 2023_for-web_ok.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\36_7th PPR  Aug2022 - July 2023_for-web_ok.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\36_PPR6_Jordan_MOPIC_For_web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\36_PPR6_Jordan_MOPIC_For_web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\37_37_For web_Copy of UNEP_Cambodia AF_PPR Year 5_3 October 2018.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\37_37_For web_Copy of UNEP_Cambodia AF_PPR Year 5_3 October 2018.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\37_37_web_UNEP_Cambodia AF_PPR_Year 6.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\37_37_web_UNEP_Cambodia AF_PPR_Year 6.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\37_37_web_UNEP_Cambodia AF_PPR_Year 7_revised_8Dec2020.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\37_37_web_UNEP_Cambodia AF_PPR_Year 7_revised_8Dec2020.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\40_40_For Website_4703_AF_Myanmar_PPR-Re-submission_Aug21_NoProcurement.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\40_40_For Website_4703_AF_Myanmar_PPR-Re-submission_Aug21_NoProcurement.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\5198_5198_MCTAF-PPR-2_for web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\5198_5198_MCTAF-PPR-2_for web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\5198_5198_Revised PPR 3_MCT for web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\5198_5198_Revised PPR 3_MCT for web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\5199_5199_PPR_SEA project_Year2_UNH-OIT_30082022_revised_for web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\5199_5199_PPR_SEA project_Year2_UNH-OIT_30082022_revised_for web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\55_55_Final2_PPR_MCCAP March 30 2016 - for website.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\55_55_Final2_PPR_MCCAP March 30 2016 - for website.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\55_55_For web_PPR_MCCAP 2017 BLZMIECoastal20111 .xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\55_55_For web_PPR_MCCAP 2017 BLZMIECoastal20111 .txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\55_55_MCCAP Adaptation Fund Progress Report 2019_FOR WEB.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\55_55_MCCAP Adaptation Fund Progress Report 2019_FOR WEB.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\55_PPR5_Amended_MCCAP2020ext_Final_web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\55_PPR5_Amended_MCCAP2020ext_Final_web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\60_60_Final For Web_ PPR Ecuador 2016-2017.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\60_60_Final For Web_ PPR Ecuador 2016-2017.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\61_61_4386_AF_Guatemala PPR 2016 15DEC2016 - for website.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\61_61_4386_AF_Guatemala PPR 2016 15DEC2016 - for website.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\61_61_4386_AF_Guatemala_PPR 8 May 18_final_for web_.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\61_61_4386_AF_Guatemala_PPR 8 May 18_final_for web_.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\61_61_For WEB_4386_AF_Guatemala_PPR_24 Jul 17.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\61_61_For WEB_4386_AF_Guatemala_PPR_24 Jul 17.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\61_61_web_PPR Guatemala 4386 -final report - 27 March 2019 resubmission.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\61_61_web_PPR Guatemala 4386 -final report - 27 March 2019 resubmission.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\6315_New PPR-AF Pekalongan 2022-revised_21_Sep_2023 - for web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\6315_New PPR-AF Pekalongan 2022-revised_21_Sep_2023 - for web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\63_63_for web_AF_PPR_Year 4_Jan172017.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\63_63_for web_AF_PPR_Year 4_Jan172017.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\63_AF_PPR_Year 5_Nov2017_Amended final_for web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\63_AF_PPR_Year 5_Nov2017_Amended final_for web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\63_AF_PPR_Year 6_2018_final - for web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\63_AF_PPR_Year 6_2018_final - for web.txt\n",
      "Processing C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\\8901_AF Malawi PPR2 April2023 - for web.xlsx...\n",
      "Saved processed text to C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\\8901_AF Malawi PPR2 April2023 - for web.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import openpyxl\n",
    "\n",
    "def excel_to_txt(excel_path, txt_path):\n",
    "    workbook = openpyxl.load_workbook(excel_path)\n",
    "    with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
    "        for ws in workbook.worksheets:\n",
    "            txt_file.write(f\"--- {ws.title} ---\\n\")  #add title //TODO: maybe add section instead of title\n",
    "            for row in ws.iter_rows(values_only=True):\n",
    "                row_values = [str(cell) if cell is not None else '' for cell in row]\n",
    "                txt_file.write('\\t'.join(row_values) + '\\n')\n",
    "            txt_file.write('\\n')  # Separate sheet with a space\n",
    "\n",
    "def process_folder(source_folder, target_folder):\n",
    "    for excel_file in glob.glob(os.path.join(source_folder, '*.xlsx')):\n",
    "        file_name = os.path.basename(excel_file)\n",
    "        txt_file_name = file_name.replace('.xlsx', '.txt')\n",
    "        txt_path = os.path.join(target_folder, txt_file_name)\n",
    "        \n",
    "        print(f\"Processing {excel_file}...\")\n",
    "        excel_to_txt(excel_file, txt_path)\n",
    "        print(f\"Saved processed text to {txt_path}\")\n",
    "\n",
    "# Paths to your source and target folders\n",
    "source_folder = r\"C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_excel\"\n",
    "target_folder = r\"C:\\Users\\david\\My Drive\\data\\analysis_git_data\\cgiar\\sample_processed_excel\"\n",
    "\n",
    "\n",
    "process_folder(source_folder, target_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save different headings in different columns  WORD\n",
    "\n",
    "//TODO: Check with Cesare if the following approaches can work. Still a bunch of cleaning but could also be a way to split sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def process_document_to_df(doc_path):\n",
    "    doc = Document(doc_path)\n",
    "    data = {}\n",
    "    current_heading = None\n",
    "\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if paragraph.style.name.startswith('Heading'):\n",
    "            current_heading = paragraph.text\n",
    "            data[current_heading] = []\n",
    "        else:\n",
    "            if current_heading:\n",
    "                data[current_heading].append(paragraph.text)\n",
    "            else:\n",
    "                pass\n",
    "    df = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in data.items()]))\n",
    "    return df\n",
    "\n",
    "\n",
    "# Path to your Word document\n",
    "doc_path = \"C:\\\\Users\\\\david\\\\My Drive\\\\data\\\\analysis_git_data\\\\cgiar\\\\AF_docs\\\\50_50_MTR-AF-Uzbekistan-Report-FINAL2.docx\"\n",
    "\n",
    "# Desired output path for the text file\n",
    "output_path ='C:\\\\Users\\\\david\\\\My Drive\\\\data\\\\analysis_git_data\\\\cgiar'\n",
    "\n",
    "# Process the document and get structured text\n",
    "structured_text = process_document_to_df(doc_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY TO SAVE ONLY FROM H1 TO H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document_to_df(doc_path):\n",
    "    doc = Document(doc_path)\n",
    "    data = {}\n",
    "    current_heading = None\n",
    "    current_content = []\n",
    "\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if paragraph.style.name == 'Heading 1':\n",
    "            if current_heading is not None:\n",
    "                data[current_heading] = \"\\n\".join(current_content)\n",
    "                current_content = []\n",
    "            current_heading = paragraph.text\n",
    "            data[current_heading] = []\n",
    "        else:\n",
    "            if current_heading:\n",
    "                current_content.append(paragraph.text)\n",
    "\n",
    "    if current_heading is not None and current_heading not in data:\n",
    "        data[current_heading] = \"\\n\".join(current_content)\n",
    "\n",
    "    df = pd.DataFrame(list(data.items()), columns=['Heading', 'Content'])\n",
    "    return df\n",
    "\n",
    "# Directory containing your Word documents\n",
    "doc_directory = \"C:\\\\Users\\\\david\\\\My Drive\\\\data\\\\analysis_git_data\\\\cgiar\\\\sample_word\"\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for filename in os.listdir(doc_directory):\n",
    "    if filename.endswith(\".docx\"):\n",
    "        doc_path = os.path.join(doc_directory, filename)\n",
    "        \n",
    "        print(f\"Processing document: {filename}\")  # Print statement added here\n",
    "        df = process_document_to_df(doc_path)\n",
    "        \n",
    "        df['Document'] = filename\n",
    "        dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True, sort=False)\n",
    "\n",
    "# Optional: save the combined DataFrame to a CSV file\n",
    "output_csv_path = os.path.join(doc_directory, 'combined_documents.csv')\n",
    "combined_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Combined DataFrame saved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
